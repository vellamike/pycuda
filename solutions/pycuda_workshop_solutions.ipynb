{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vellamike/pycuda/blob/master/pycuda_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2JZt1GL5D6W"
   },
   "source": [
    "# Introduction to CUDA and PyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FA_YN7HlGRP5"
   },
   "outputs": [],
   "source": [
    "!pip install pycuda # install cuda\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-g92eSBn5FlC"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(1729)\n",
    "a = numpy.random.randn(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bqm9uTBzJf9X"
   },
   "outputs": [],
   "source": [
    "a = a.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "92L9E7WkJhsy"
   },
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1xaAt_NJjSb"
   },
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(a_gpu, a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bSAkS6e2Jk38"
   },
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "  __global__ void doublify(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] *= 2;\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fBQ0blkNJnIg"
   },
   "outputs": [],
   "source": [
    "func = mod.get_function(\"doublify\")\n",
    "func(a_gpu, block=(4,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ef82NDPJqWV"
   },
   "outputs": [],
   "source": [
    "a_doubled = numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
    "print(a_doubled)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXx_p97mJs4Z"
   },
   "outputs": [],
   "source": [
    "b = numpy.random.randn(4,4)\n",
    "b = b.astype(numpy.float32)\n",
    "c = numpy.random.randn(4,4)\n",
    "c = c.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQYD348qKgva"
   },
   "outputs": [],
   "source": [
    "mod2 = SourceModule(\"\"\"\n",
    "  __global__ void add2(float *a, float *b)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] += b[idx];\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vs_5Hb-6Kr-C"
   },
   "outputs": [],
   "source": [
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "c_gpu = cuda.mem_alloc(c.nbytes)\n",
    "\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "cuda.memcpy_htod(c_gpu, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwA4tpOtLE5_"
   },
   "outputs": [],
   "source": [
    "func = mod2.get_function(\"add2\")\n",
    "func(b_gpu,c_gpu, block=(4,4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zN8iBYDM_00"
   },
   "outputs": [],
   "source": [
    "added = numpy.empty_like(b)\n",
    "cuda.memcpy_dtoh(added, b_gpu)\n",
    "print(added)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vJBVoR8ANgx5"
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. Write a cuda kernel to find the elementwise square of a matrix\n",
    "2. Write a cuda kernel to find a matrix, which when added to the given matrix results in every element being equal to zero\n",
    "3. Write a cuda kernel to multiply two matrices:\n",
    "    1. Assume square matrices, with dimensions < 1024\n",
    "    2. Assume square matrices, with dimensions > 1024\n",
    "    3. Assume non-square matrices, with dimensions > 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBYr6BUWNuLe"
   },
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod3 = SourceModule(\"\"\"\n",
    "  __global__ void square2(float *a, int size)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*size;\n",
    "    a[idx] *= a[idx];\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 7\n",
    "\n",
    "numpy.random.seed(945)\n",
    "d = numpy.random.randn(size,size)\n",
    "d = d.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gpu = cuda.mem_alloc(d.nbytes)\n",
    "cuda.memcpy_htod(d_gpu, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod3.get_function(\"square2\")\n",
    "func(d_gpu, numpy.int32(size), block=(size,size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared = numpy.empty_like(d)\n",
    "cuda.memcpy_dtoh(squared, d_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(d)\n",
    "#print(squared)\n",
    "\n",
    "print(numpy.max(numpy.abs(squared - d*d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod4 = SourceModule(\"\"\"\n",
    "  __global__ void minus(float *a, int size)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*size;\n",
    "    a[idx] = -a[idx];\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 7\n",
    "\n",
    "numpy.random.seed(9574)\n",
    "d = numpy.random.randn(size,size)\n",
    "d = d.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_gpu = cuda.mem_alloc(d.nbytes)\n",
    "cuda.memcpy_htod(d_gpu, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod4.get_function(\"minus\")\n",
    "func(d_gpu, numpy.int32(size), block=(size,size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complement = numpy.empty_like(d)\n",
    "cuda.memcpy_dtoh(complement, d_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(d)\n",
    "#print(complement)\n",
    "\n",
    "print(numpy.max(numpy.abs(d + complement)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   A. Assume square matrices, with dimensions < 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod5 = SourceModule(\"\"\"\n",
    "  __global__ void multiplyA(float *a, float *b, float *c, int size)\n",
    "  {\n",
    "    int row = threadIdx.x; \n",
    "    int col = threadIdx.y;\n",
    "    \n",
    "    c[col + row * size] = 0;\n",
    "    for(int i=0; i<size; ++i){\n",
    "        c[col + row * size] += a[i + row * size] * b[col + i * size];\n",
    "    }\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 8\n",
    "\n",
    "numpy.random.seed(9574)\n",
    "\n",
    "a = numpy.random.randn(size,size)\n",
    "a = a.astype(numpy.float32)\n",
    "\n",
    "b = numpy.random.randn(size,size)\n",
    "b = b.astype(numpy.float32)\n",
    "\n",
    "c = numpy.empty_like(a)\n",
    "c = c.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "\n",
    "c_gpu = cuda.mem_alloc(c.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod5.get_function(\"multiplyA\")\n",
    "func(a_gpu, b_gpu, c_gpu, numpy.int32(size), block=(size,size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(c, c_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a@b)\n",
    "#print(c)\n",
    "\n",
    "print(numpy.max(numpy.abs(c - a@b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Assume square matrices, with dimensions > 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod6 = SourceModule(\"\"\"\n",
    "  __global__ void multiplyB(float *a, float *b, float *c, int size)\n",
    "  {\n",
    "    int row = threadIdx.x + blockDim.x * blockIdx.x; \n",
    "    int col = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "    \n",
    "    if (row < size && col < size){\n",
    "        c[col + row * size] = 0;\n",
    "        for(int i=0; i<size; ++i){\n",
    "            c[col + row * size] += a[i + row * size] * b[col + i * size];\n",
    "        } \n",
    "    }\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 56\n",
    "\n",
    "numpy.random.seed(494)\n",
    "\n",
    "a = numpy.random.randn(size,size)\n",
    "a = a.astype(numpy.float32)\n",
    "\n",
    "b = numpy.random.randn(size,size)\n",
    "b = b.astype(numpy.float32)\n",
    "\n",
    "c = numpy.empty_like(a)\n",
    "c = c.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "\n",
    "c_gpu = cuda.mem_alloc(c.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 32\n",
    "grid_size = (size + block_size - 1) // block_size # Number of needed blocks to cover the whole matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod6.get_function(\"multiplyB\")\n",
    "func(a_gpu, b_gpu, c_gpu, numpy.int32(size), block=(block_size,block_size,1), grid=(grid_size,grid_size,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(c, c_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a@b)\n",
    "#print(c)\n",
    "\n",
    "print(numpy.max(numpy.abs(c - a@b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Assume non-square matrices, with dimensions > 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod7 = SourceModule(\"\"\"\n",
    "  __global__ void multiplyC(float *a, float *b, float *c, int n, int m, int p)\n",
    "  {\n",
    "    int row = threadIdx.x + blockDim.x * blockIdx.x; \n",
    "    int col = threadIdx.y + blockDim.y * blockIdx.y;\n",
    "    \n",
    "    if (row < n && col < m){\n",
    "        c[col + row * m] = 0;\n",
    "        for(int i=0; i<p; ++i){\n",
    "            c[col + row * m] += a[i + row * p] * b[col + i * m];\n",
    "        } \n",
    "    }\n",
    "  }\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 36\n",
    "p = 48\n",
    "m = 72\n",
    "\n",
    "numpy.random.seed(5867)\n",
    "\n",
    "a = numpy.random.randn(n,p)\n",
    "a = a.astype(numpy.float32)\n",
    "\n",
    "b = numpy.random.randn(p,m)\n",
    "b = b.astype(numpy.float32)\n",
    "\n",
    "c = numpy.zeros([n,m])\n",
    "c = c.astype(numpy.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "cuda.memcpy_htod(b_gpu, b)\n",
    "\n",
    "c_gpu = cuda.mem_alloc(c.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size_x = min(n, 32) \n",
    "grid_size_x = (n + block_size_x - 1) // block_size_x\n",
    "\n",
    "block_size_y = min(m, 32)\n",
    "grid_size_y = (m + block_size_y - 1) // block_size_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod7.get_function(\"multiplyC\")\n",
    "func(a_gpu, b_gpu, c_gpu, \n",
    "     numpy.int32(n), numpy.int32(m), numpy.int32(p), \n",
    "     block=(block_size_x,block_size_y,1), grid=(grid_size_x,grid_size_y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_dtoh(c, c_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a@b)\n",
    "#print(c)\n",
    "\n",
    "print(numpy.max(numpy.abs(c - a@b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "pycuda workshop",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
